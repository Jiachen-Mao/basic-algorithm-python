{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kNN on Iris\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "np.unique(iris_y)\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test = iris_X[indices[-10:]]\n",
    "iris_y_test = iris_y[indices[-10:]]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(iris_X_train, iris_y_train)\n",
    "KNeighborsClassifier(algorithm = 'auto', leaf_size = 30, metric = 'minkowski', metric_params = None,\n",
    "                    n_jobs = None, n_neighbors= 5, p = 2, weights = 'uniform')\n",
    "print(knn.predict(iris_X_test))\n",
    "print(iris_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear regression\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X_train = diabetes.data[:-20]\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_X_test = diabetes.data[-20:]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "linear_model.LinearRegression(copy_X = True, fit_intercept = True, n_jobs = None, normalize = False)\n",
    "print(regr.coef_)\n",
    "\n",
    "np.mean((regr.predict(diabetes_X_test) - diabetes_y_test)**2)\n",
    "\n",
    "regr.score(diabetes_X_test, diabetes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge regression\n",
    "\n",
    "X = np.c_[.5, 1].T\n",
    "y = [.5, 1]\n",
    "test = np.c_[0, 2].T\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "np.random.seed(0)\n",
    "for _ in range(6):\n",
    "    this_X = .1 * np.random.normal(size = (2, 1)) + X\n",
    "    regr.fit(this_X, y)\n",
    "    plt.plot(test, regr.predict(test))\n",
    "    plt.scatter(this_X, y, s = 3)\n",
    "\n",
    "regr = linear_model.Ridge(alpha = .1)\n",
    "plt.figure()\n",
    "\n",
    "np.random.seed(0)\n",
    "for _ in range(6):\n",
    "    this_X = .1 * np.random.normal(size = (2, 1)) + X\n",
    "    regr.fit(this_X, y)\n",
    "    plt.plot(test, regr.predict(test))\n",
    "    plt.scatter(this_X, y, s = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LASSO regression\n",
    "\n",
    "regr = linear_model.Lasso()\n",
    "alphas = np.logspace(-4, -1, 6)\n",
    "scores = [regr.set_params(alpha = alpha).fit(diabetes_X_train, diabetes_y_train).score(diabetes_X_test, diabetes_y_test) for alpha in alphas]\n",
    "best_alpha = alphas[scores.index(max(scores))]\n",
    "regr.alpha = best_alpha\n",
    "\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "linear_model.Lasso(copy_X = True, fit_intercept = True, max_iter = 1000, normalize = False, positive = False,\n",
    "                  precompute = False, random_state = None, selection = 'cyclic', tol = 0.0001, warm_start = False)\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression\n",
    "\n",
    "log = linear_model.LogisticRegression(solver = 'lbfgs', C = 1e5, multi_class = 'multinomial')\n",
    "\n",
    "log.fit(iris_X_train, iris_y_train)\n",
    "linear_model.LogisticRegression(C = 100000.0, class_weight = None, dual = False, fit_intercept = True, intercept_scaling = 1,\n",
    "                               max_iter = 100, multi_class = 'multinomial', n_jobs = None, penalty = 'l2', random_state = None,\n",
    "                               solver = 'lbfgs', tol = 0.0001, verbose = 0, warm_start = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## support vector machine\n",
    "\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel = 'rbf')\n",
    "svc.fit(iris_X_train, iris_y_train)\n",
    "svm.SVC(C = 1.0, cache_size = 200, class_weight = None, coef0 = 0.0, decision_function_shape = 'ovr', gamma = 'auto_deprecated', \n",
    "        max_iter = -1, probability = False, random_state = None, shrinking = True, tol = 0.001, verbose = False)\n",
    "\n",
    "print(svc.predict(iris_X_test))\n",
    "print(iris_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score\n",
    "\n",
    "from sklearn import datasets, svm, linear_model\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "svc = svm.SVC(C = 1, kernel = 'linear')\n",
    "svc.fit(X_digits[:-100], y_digits[:-100]).score(X_digits[-100:], y_digits[-100:])\n",
    "\n",
    "X_folds = np.array_split(X_digits, 3)\n",
    "y_folds = np.array_split(y_digits, 3)\n",
    "scores = list()\n",
    "\n",
    "for k in range(3):\n",
    "    X_train = list(X_folds)\n",
    "    X_test = X_train.pop(k)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = list(y_folds)\n",
    "    y_test = y_train.pop(k)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross-validation\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X = ['a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'c', 'c']\n",
    "k_fold = KFold(n_splits = 5)\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    print('train: %s | test %s' % (train_indices, test_indices))\n",
    "\n",
    "[svc.fit(X_digits[train], y_digits[train]).score(X_digits[test], y_digits[test]) for train, test in k_fold.split(X_digits)]\n",
    "\n",
    "cross_val_score(svc, X_digits, y_digits, cv = k_fold, n_jobs = -1)\n",
    "\n",
    "cross_val_score(svc, X_digits, y_digits, cv = k_fold, scoring = 'precision_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "Cs = np.logspace(-6, -1, 10)\n",
    "clf = GridSearchCV(estimator = svc, param_grid = dict(C = Cs), n_jobs = -1)\n",
    "clf.fit(X_digits[:1000], y_digits[:1000])\n",
    "\n",
    "clf.best_score_\n",
    "\n",
    "clf.best_estimator_.C\n",
    "\n",
    "clf.score(X_digits[1000:], y_digits[1000:])\n",
    "\n",
    "cross_val_score(clf, X_digits, y_digits)\n",
    "\n",
    "\n",
    "lasso = linear_model.LassoCV(cv = 3)\n",
    "diabetes = datasets.load_diabetes()\n",
    "X_diabetes = diabetes.data\n",
    "y_diabetes = diabetes.target\n",
    "lasso.fit(X_diabetes, y_diabetes)\n",
    "linear_model.LassoCV(alphas = None, copy_X = True, cv = 3, eps = 0.001, fit_intercept = True,\n",
    "                    max_iter = 1000, n_alphas = 100, n_jobs = None, normalize = False,\n",
    "                    positive = False, precompute = 'auto', random_state = None,\n",
    "                    selection = 'cyclic', tol = 0.0001, verbose = False)\n",
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-means clustering\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters = 3)\n",
    "k_means.fit(X_iris)\n",
    "cluster.KMeans(algorithm = 'auto', copy_x = True, init = 'k-means++')\n",
    "print(k_means.labels_[::10])\n",
    "print(y_iris[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vector quantization\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    face = sp.face(gray = True)\n",
    "except AttributeError:\n",
    "    from scipy import misc\n",
    "    face = misc.face(gray = True)\n",
    "    \n",
    "X = face.reshape((-1, 1))\n",
    "k_means = cluster.KMeans(n_clusters = 5, n_init = 1)\n",
    "k_means.fit(X)\n",
    "cluster.KMeans(algorithm = 'auto', copy_x = True, init = 'k-mean++')\n",
    "\n",
    "values = k_means.cluster_centers_.squeeze()\n",
    "labels = k_means.labels_\n",
    "face_compressed = np.choose(labels, values)\n",
    "face_compressed.shape = face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## connectivity-constrained clustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import coins\n",
    "from skimage.transform import rescale\n",
    "from sklearn.feature_extraction.image import grid_to_graph\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "orig_coins = coins()\n",
    "\n",
    "smoothed_coins = sp.ndimage.filters.gaussian_filter(orig_coins, sigma = 2)\n",
    "rescaled_coins = rescale(smoothed_coins, 0.2, mode = 'reflect')\n",
    "\n",
    "X = np.reshape(rescaled_coins, (-1, 1))\n",
    "\n",
    "connectivity = grid_to_graph(*rescaled_coins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## principle component analysis\n",
    "\n",
    "x1 = np.random.normal(size = 100)\n",
    "x2 = np.random.normal(size = 100)\n",
    "x3 = x1 + x2\n",
    "X = np.c_[x1, x2, x3]\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "decomposition.PCA(copy = True, iterated_power = 'auto', n_components = None, random_state = None,\n",
    "                 svd_solver = 'auto', tol = 0.0, whiten = False)\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "pca.n_components = 2\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## independent component analysis\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "time = np.linspace(0, 10, 2000)\n",
    "s1 = np.sin(2*time)\n",
    "s2 = np.sign(np.sin(3*time))\n",
    "s3 = signal.sawtooth(2 * np.pi * time)\n",
    "S = np.c_[s1, s2, s3]\n",
    "\n",
    "S += 0.2 * np.random.normal(size = S.shape)\n",
    "S /= S.std(axis = 0)\n",
    "\n",
    "A = np.array([[1,1,1], [0.5,2,1], [1.5,1,2]])\n",
    "X = np.dot(S, A.T)\n",
    "\n",
    "ica = decomposition.FastICA()\n",
    "S_ = ica.fit_transform(X)\n",
    "A_ = ica.mixing_.T\n",
    "np.allclose(X, np.dot(S_, A_) + ica.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
